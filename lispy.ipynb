{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11fc296d-c69f-48c7-b65c-c760d7aef6bf",
   "metadata": {},
   "source": [
    "# Lispy\n",
    "\n",
    "This notebook builds, step-by-step a simple lisp-ish interpreter. I made this in the process of applying for the [recurse center](https://www.recurse.com/apply/retreat) and kind of got a little carried away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9382bd-5a65-4f8d-8939-53b7cff82de4",
   "metadata": {},
   "source": [
    "## Parser\n",
    "\n",
    "First let's write a tokenizer/parser. We'll write code that takes some Lisp code and returns an abstract syntax tree. The AST should represent the structure of the code and the meaning of each token. For example give\n",
    "\n",
    "```(first (list 1 (+ 2 3) 9))```\n",
    "\n",
    "It should return a nested array like \n",
    "\n",
    "```[\"first\", [\"list\", 1, [\"+\", 2, 3], 9]]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b993f58f-71e0-4461-af7d-b595620736ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = ['(', ')']\n",
    "separator = ' ', '\\n'\n",
    "string_delim = [\"'\", '\"']\n",
    "result = []\n",
    "\n",
    "def tokenize(code, nextToken='', result=None):\n",
    "    if result is None:\n",
    "        result = []        \n",
    "    \n",
    "    if len(code) == 0:\n",
    "        return result or nextToken # deals with naked literals\n",
    "\n",
    "    nextChar, rest = code[0], code[1:]\n",
    "    \n",
    "    if nextChar in delimiter:\n",
    "        if nextChar == '(':\n",
    "            return tokenize(rest, '', result + [nextChar])\n",
    "        if nextChar == ')':\n",
    "            if nextToken != '':\n",
    "                return tokenize(rest, '', result + [nextToken, nextChar])\n",
    "            else:\n",
    "                return tokenize(rest, '', result + [nextChar])\n",
    "    \n",
    "    if nextChar in separator:\n",
    "        if nextToken != '':\n",
    "            return tokenize(rest, '', result + [nextToken])\n",
    "        else:\n",
    "            return tokenize(rest, '', result)\n",
    "        \n",
    "    # Properly tokenize strings\n",
    "    if nextChar in string_delim:\n",
    "        for i in range(len(rest)):\n",
    "            if rest[i] == nextChar: # check for closing string delim\n",
    "                return tokenize(rest[i+1:], '', result + [\"\\\"{}\\\"\".format(rest[:i])])\n",
    "            \n",
    "        raise Exception(\"Malformed input, unterminated string\")\n",
    "    \n",
    "    return tokenize(rest, nextToken + nextChar, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c4726e-8251-449d-a852-937f19306fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(tokens, ast=None, depth=0, balance=0):    \n",
    "    if ast is None:\n",
    "        ast = []\n",
    "        \n",
    "    if len(tokens) == 0:\n",
    "        if depth == 0:\n",
    "            assert balance == 0, \"Unbalanced expression\"\n",
    "            \n",
    "        return ast, tokens, balance\n",
    "    \n",
    "    nextToken, rest = tokens[0], tokens[1:]\n",
    "    \n",
    "    if nextToken in delimiter:\n",
    "        if nextToken == '(':\n",
    "            nextExpression, rest, new_balance = parser(rest, depth=depth+1, balance=balance+1)\n",
    "            ast.append(nextExpression)\n",
    "            \n",
    "            return parser(rest, ast, depth=depth, balance=new_balance)\n",
    "        if nextToken == ')':  \n",
    "            balance -= 1\n",
    "            assert balance >= 0, \"Unbalanced expression\"\n",
    "            return ast, rest, balance\n",
    "            \n",
    "    return parser(rest, ast + [nextToken], depth=depth, balance=balance)\n",
    "\n",
    "def parse(tokens):\n",
    "    return parser(tokens)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca531aab-d7dc-4500-b3a8-9d8517ee3625",
   "metadata": {},
   "source": [
    "## Let's test the 💩 out of this tokenizer/parser\n",
    "\n",
    "Otherwise this thing probably sucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c0fe94-9441-45cb-a23d-eaafbfa9563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "literal_code = \"1\"\n",
    "simple_code = \"(first (list 1 (+ 2 3) 9))\" \n",
    "challenge_code = \"\"\"\n",
    "(defun fibonacci (N)\n",
    "  (if (or (zerop N) (= N 1))\n",
    "      1\n",
    "    (+ (fibonacci (- N 1)) (fibonacci (- N 2)))))\n",
    "\"\"\"\n",
    "\n",
    "malformed_code_l = '(()'\n",
    "malformed_code_r = '())'\n",
    "\n",
    "class TokenizerTests(unittest.TestCase):\n",
    "    def test_literal(self):\n",
    "        self.assertEqual(tokenize(literal_code), \"1\")\n",
    "    \n",
    "    def test_strings(self):\n",
    "        self.assertEqual(tokenize(\"\"\"(1 \"hello world\" 'wassup')\"\"\"), ['(', '1', '\"hello world\"', '\"wassup\"', ')'])\n",
    "\n",
    "    def test_malformed_strings1(self):\n",
    "        self.assertRaises(Exception, lambda: tokenize(\"\"\"(1 \"hello world)\"\"\"))\n",
    "\n",
    "    def test_malformed_strings2(self):\n",
    "        self.assertRaises(Exception, lambda: tokenize(\"\"\"(1 'hello world)\"\"\"))\n",
    "\n",
    "    def test_simple(self):\n",
    "        self.assertEqual(tokenize(simple_code), ['(', 'first', '(', 'list', '1', '(', '+', '2', '3', ')', '9', ')', ')'])\n",
    "        \n",
    "    def test_challenge(self):\n",
    "        self.assertEqual(tokenize(challenge_code), \n",
    "                         ['(', 'defun', 'fibonacci', '(', 'N', ')', '(', 'if', '(', 'or', '(', 'zerop', 'N', ')', \n",
    "                          '(', '=', 'N', '1', ')', ')', '1', '(', '+', '(', 'fibonacci', '(', '-', 'N', '1', ')', ')', \n",
    "                          '(', 'fibonacci', '(', '-', 'N', '2', ')', ')', ')', ')', ')'])\n",
    "\n",
    "        \n",
    "class ParserTests(unittest.TestCase):    \n",
    "    def test_literal(self):\n",
    "        self.assertEqual(parse(tokenize(literal_code)), ['1'])\n",
    "    \n",
    "    def test_simple(self):\n",
    "        self.assertEqual(parse(tokenize(simple_code)), [['first', ['list', '1', ['+', '2', '3'], '9']]])\n",
    "        \n",
    "    def test_challenge(self):\n",
    "        self.assertEqual(parse(tokenize(challenge_code)), \n",
    "                         [['defun', 'fibonacci', ['N'], \n",
    "                           ['if', ['or', ['zerop', 'N'], ['=', 'N', '1']], '1', \n",
    "                            ['+', ['fibonacci', ['-', 'N', '1']], ['fibonacci', ['-', 'N', '2']]]]]])\n",
    "        \n",
    "    def test_malformed_l(self):\n",
    "        self.assertRaises(Exception, lambda: parse(tokenize(malformed_code_l)))\n",
    "    \n",
    "    def test_malformed_r(self):\n",
    "        self.assertRaises(Exception, lambda: parse(tokenize(malformed_code_r)))\n",
    "    \n",
    "unittest.main(argv=[''], verbosity=1, exit=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d179afb-a5f1-4eee-80ba-a7d20338208c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 🚀 Lisp Interpreter\n",
    "\n",
    "Get a list of ASTs and run them 🏃‍♂️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9b20f5-1b5a-43a4-9cd5-12ca65f6b008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0abc0bd-80e4-4a23-ae5b-85c4a36d4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"hello/world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e41dc8-445c-423e-a0b2-c8e1703db0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hello', 'world')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = a.split('/')\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154ea5e5-1cd5-4bb5-8473-72b260f4e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "module_delim = '/'\n",
    "\n",
    "def resolve(ast, **env):\n",
    "    # String literals\n",
    "    if ast[0] in string_delim:\n",
    "        return ast[1:-1], env\n",
    "\n",
    "    # Ints\n",
    "    if re.fullmatch('\\d+', ast):\n",
    "        return int(ast), env\n",
    "\n",
    "    # Floats\n",
    "    if re.fullmatch('\\d+\\.\\d*', ast):\n",
    "        return float(ast), env\n",
    "\n",
    "    # Lastly check for symbols defined in the env\n",
    "    \n",
    "    # Check for modules, which keep their environments as nested dicts in the env\n",
    "    if module_delim in ast and len(ast) > 1:\n",
    "        module_name, symbol = ast.split(module_delim)\n",
    "        \n",
    "        if module_name not in env:\n",
    "            raise Exception(f\"Module not found - {module_name}\")\n",
    "        \n",
    "        return env[module_name][symbol], env\n",
    "    \n",
    "    # Top level symbols\n",
    "    return env[ast], env\n",
    "\n",
    "def evaluate(ast, **env):\n",
    "    if isinstance(ast, str):        \n",
    "        return resolve(ast, **env)\n",
    "    \n",
    "    if isinstance(ast, list):\n",
    "        assert len(ast) >= 1, \"Empty expression\"\n",
    "        \n",
    "        op_name = ast[0]        \n",
    "        operation, _ = evaluate(op_name, **env) \n",
    "\n",
    "        if op_name in macros:\n",
    "            # Macros are in charge of evalauting the ast of its body, and returning a tuple (result, env) potentially modifying the env\n",
    "            return operation(*ast[1:], **env)\n",
    "        \n",
    "        # Otherwise we evaluate everything before giving it to the operation\n",
    "        args = []\n",
    "        for x in ast[1:]:\n",
    "            arg, env = evaluate(x, **env) # Things could mutate the env during the evaluation, although seems like a terrible idea\n",
    "            args.append(arg)\n",
    "        \n",
    "        # Normal procedure calls only get passed their args\n",
    "        return operation(*args), env\n",
    "    \n",
    "    # Only used if the thing is already evaluated, this is probably wrong\n",
    "    return ast, env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed8d9e-22f8-4135-9bb5-66fd2bc2fcb1",
   "metadata": {},
   "source": [
    "# 🏗 Functions & Macros\n",
    "\n",
    "Now that we have an interpreter that works, we have to define the basic building blocks of the language. \n",
    "\n",
    "## Functions \n",
    "These are your run of the mill functions that you know and love. They look something like this:\n",
    "\n",
    "```python\n",
    "def my_func(*args):\n",
    "    '''args have already been evaluated'''\n",
    "    ...do something cool here...\n",
    "```    \n",
    "\n",
    "## Macros\n",
    "These are a bit more interesting and more powerful. They get passed the _unevaluated_ `ast` as well as the environment, and they have to return a tuple of (result, env) where result has been evaluated.\n",
    "\n",
    "```python\n",
    "def my_macro(*ast, **env):\n",
    "    '''args have already been evaluated'''\n",
    "    ...do something very cool here...\n",
    "```    \n",
    "\n",
    "Things that full under macros include most of the actual syntax, including `if`, `or`, `when`, `defn`, `let`, etc.\n",
    "\n",
    "## NB\n",
    "\n",
    "Below I defined several foundational functions that all call out to Python. However, it's clear that many could just be `defn`d in the language itself as a \"core\" library. These is actually pretty cool, and is left as an exercise to the reader 😉.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "155a15d6-92ed-4c7d-90e3-880555dbdca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def addition_op(*args):\n",
    "    acc = 0\n",
    "    for x in args:\n",
    "        acc += x\n",
    "    return acc\n",
    "\n",
    "def subtraction_op(*args):\n",
    "    a, b = args[0], args[1]\n",
    "    return a - b\n",
    "\n",
    "def multiply_op(*args):\n",
    "    acc = 1\n",
    "    for x in args:\n",
    "        acc *= x\n",
    "    return acc\n",
    "\n",
    "def range_op(*args):\n",
    "    return list(range(*args))\n",
    "\n",
    "def reduce_op(*args):\n",
    "    f, init, xs = args[0], args[1], args[2]\n",
    "    \n",
    "    acc = init\n",
    "    for x in xs:\n",
    "        acc = f(acc, x)\n",
    "    return acc\n",
    "\n",
    "def list_op(*args):\n",
    "    return list(args)\n",
    "\n",
    "def cat_op(*args):\n",
    "    acc = []\n",
    "    for x in args:\n",
    "        acc += x\n",
    "    return acc\n",
    "\n",
    "def len_op(*args):\n",
    "    return len(*args)\n",
    "\n",
    "def eq_op(*args):\n",
    "    a, b = args[0], args[1]\n",
    "    return a == b\n",
    "    \n",
    "def gt_op(*args):\n",
    "    a, b = args[0], args[1]\n",
    "    return a > b\n",
    "\n",
    "def lt_op(*args):\n",
    "    a, b = args[0], args[1]\n",
    "    return a < b\n",
    "\n",
    "def print_op(*args):\n",
    "    print(*args)\n",
    "    return None\n",
    "\n",
    "def format_op(*args):\n",
    "    format_str, xs = args[0], args[1:]\n",
    "    print(format_str.format(*xs))    \n",
    "    return None\n",
    "\n",
    "def str_op(*args):\n",
    "    acc = ''\n",
    "    for x in args:\n",
    "        acc += str(x)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def type_op(*args):\n",
    "    return type(args[0])\n",
    "\n",
    "\n",
    "############\n",
    "## Macros ##\n",
    "############\n",
    "def let_op(*ast, **env):\n",
    "    '''Evaluates expression with modified environment\n",
    "        \n",
    "        (let (a 2 b 3)\n",
    "            (+ a b))\n",
    "    '''\n",
    "    \n",
    "    definitions, body = ast[0], ast[1]    \n",
    "\n",
    "    assert len(definitions) % 2 == 0, \"Let definitions must be in pairs\"\n",
    "\n",
    "    newEnv = dict(env) # copy the env to not overwrite it\n",
    "    for i in range(0, len(definitions), 2):\n",
    "        key, value = definitions[i], evaluate(definitions[i+1], **newEnv)[0]\n",
    "        newEnv[key] = value\n",
    "         \n",
    "    return evaluate(body, **newEnv)[0], env\n",
    "\n",
    "def def_op(*ast, **env):\n",
    "    '''Allows for definition of bindings that can be referenced later. Mutates global env\n",
    "        >> (def a 1)\n",
    "        >> a\n",
    "        1\n",
    "    '''\n",
    "    key, value_expr = ast[0], ast[1]\n",
    "    value, _ = evaluate(value_expr, **env)\n",
    "    \n",
    "    env[key] = value\n",
    "    return value, env\n",
    "\n",
    "def fn_op(*ast, **env):\n",
    "    '''Creates new anonymous function object and returns it'''\n",
    "    signature, body = ast[0], ast[1]    \n",
    "    \n",
    "    def new_op(*args): \n",
    "        innerEnv = dict(env) # avoid mutating the global env\n",
    "        for arg_name, arg_value in zip(signature, args):\n",
    "            innerEnv[arg_name] = arg_value\n",
    "        return evaluate(body, **innerEnv)[0] # We're defining a normal function (not a macro), thus we must not return the env coming from `evaluate`\n",
    "    \n",
    "    return new_op, env\n",
    "\n",
    "def defn_op(*ast, **env):\n",
    "    '''Defines a function and adds it to the global environment\n",
    "    \n",
    "        >> (defn my_sum (a b c) (+ a b c))\n",
    "        >> (myfunc 1 2 3)\n",
    "        6\n",
    "    '''\n",
    "    name, signature, body = ast[0], ast[1], ast[2]\n",
    "    \n",
    "    def new_op(*args): \n",
    "        innerEnv = {} # avoid mutating the global env\n",
    "        for arg_name, arg_value in zip(signature, args):\n",
    "            innerEnv[arg_name] = arg_value\n",
    "        \n",
    "        return evaluate(body, **dict(innerEnv, **env))[0]    \n",
    "    \n",
    "    env[name] = new_op\n",
    "    return new_op, env\n",
    "\n",
    "def if_op(*ast, **env):\n",
    "    ''' Allows for conditional evaluation. The false branch does not get evaluated at all\n",
    "    \n",
    "    (if condition\n",
    "        true_branch\n",
    "        false_branch)\n",
    "    '''\n",
    "    condition, true_branch, false_branch = ast[0], ast[1], ast[2]\n",
    "    \n",
    "    if evaluate(condition, **env)[0]:\n",
    "        return evaluate(true_branch, **env)\n",
    "    else:\n",
    "        return evaluate(false_branch, **env)\n",
    "\n",
    "def do_op(*ast, **env):\n",
    "    '''Evaluates all the expressions and returns the result of the last one'''\n",
    "    result = None\n",
    "    for expr in ast:\n",
    "        result, env = evaluate(expr, **env)    \n",
    "    return result, env\n",
    "    \n",
    "def when_op(*ast, **env):\n",
    "    condition, branch = ast[0], ast[1]\n",
    "    \n",
    "    if evaluate(condition, **env)[0]:\n",
    "        return evaluate(branch, **env)\n",
    "        \n",
    "    return None, env\n",
    "\n",
    "def or_op(*ast, **env):\n",
    "    '''Evaluates expressions left to r and returns the first truthy one'''\n",
    "    \n",
    "    for expression in ast:\n",
    "        result, _ = evaluate(expression, **env)\n",
    "        if result:\n",
    "            return result, env\n",
    "    \n",
    "    return None, env\n",
    "\n",
    "def import_op(*ast, **env):\n",
    "    '''\n",
    "    Allows evaluating a module by providing its location like so\n",
    "    \n",
    "    (import \"./my/cool/mycode\")\n",
    "    \n",
    "    This will evaluate all the code under the file \"./my/cool/mycode.lspy\".\n",
    "    '''\n",
    "    \n",
    "    import_path = ast[0]\n",
    "    module_name = Path(import_path).stem\n",
    "\n",
    "    if len(ast) >= 2:\n",
    "        if isinstance(ast[1], str):\n",
    "            module_name = ast[1]\n",
    "    \n",
    "    with open(import_path[1:-1]) as import_file:\n",
    "        import_source = import_file.read()\n",
    "    \n",
    "    _, module_env = interpret(import_source, env=dict(env), output_env=True)\n",
    "\n",
    "    if module_name != '*':\n",
    "        env[module_name] = {}\n",
    "\n",
    "    # Add the new env entries added by the module_env to the top level env\n",
    "    # The module definitions get put in a subdictionary, except if the module_name is '*'\n",
    "    for symbol in module_env: \n",
    "        if symbol not in env:\n",
    "            if module_name == '*':\n",
    "                env[symbol] = module_env[symbol]\n",
    "            else:\n",
    "                env[module_name][symbol] = module_env[symbol]                \n",
    "        \n",
    "    return None, env\n",
    "    \n",
    "operators = {\n",
    "    '+': addition_op,\n",
    "    '-': subtraction_op,\n",
    "    '*': multiply_op,\n",
    "    'list': list_op,\n",
    "    'range': range_op,\n",
    "    'concat': cat_op,\n",
    "    'reduce': reduce_op,\n",
    "    'len': len_op,\n",
    "    '=': eq_op,\n",
    "    '>': gt_op,\n",
    "    '<': lt_op,\n",
    "    'True': True,\n",
    "    'False': False,\n",
    "    'None': None,\n",
    "    'print': print_op,\n",
    "    'format': format_op,\n",
    "    'str': str_op,\n",
    "    'type': type_op,\n",
    "}\n",
    "\n",
    "# This is a special dict that contains all macros\n",
    "macros = {\n",
    "    'let': let_op,\n",
    "    'def': def_op,\n",
    "    'fn': fn_op,\n",
    "    'defn': defn_op,\n",
    "    'if': if_op,\n",
    "    'or': or_op,\n",
    "    'do': do_op,\n",
    "    'when': when_op,\n",
    "    'or': or_op,   \n",
    "    'import': import_op,\n",
    "}\n",
    "\n",
    "def lisp_eval(asts, env=None):\n",
    "    if env is None:\n",
    "        env = dict(operators, **macros) \n",
    "\n",
    "    result = None\n",
    "    for ast in asts:\n",
    "        result, env = evaluate(ast, **env) # potentially mutate env\n",
    "    return result, env\n",
    "\n",
    "def interpret(code, env=None, output_env=False):\n",
    "    if env is None:\n",
    "        env = dict(operators, **macros)\n",
    "    \n",
    "    if output_env is True:\n",
    "        return lisp_eval(parse(tokenize(code)), env)\n",
    "    return lisp_eval(parse(tokenize(code)), env)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9baf921-5230-4c12-b8f7-8394ef2c4bf8",
   "metadata": {},
   "source": [
    "# 👋🏽 Hello World\n",
    "\n",
    "Here are some code examples, and no language is complete without a good hello world to begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "643e556f-d414-4891-bb73-217278d3d459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "interpret('''\n",
    "(defn greeter (name)\n",
    "    (print (str \"hello \" name)))\n",
    "\n",
    "(greeter \"world\")\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0e7ac-6356-47d3-afda-4e3377f3a5ae",
   "metadata": {},
   "source": [
    "## 🗺 Map\n",
    "\n",
    "As mentioned before, we can actually implement new functions inside of our new cool language rather than calling out to python. One good example is `map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4cffbec-ddc3-4268-9dd7-01b5a5cda864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9, 25, 49, 81]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpret('''\n",
    "(defn map (f xs)\n",
    "    (reduce (fn (acc x) (concat acc (list (f x)))) \n",
    "    (list) xs)\n",
    ")\n",
    "\n",
    "(map (fn (x) (* x x)) (range 1 10 2))\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cfbba-1de6-4440-b4fa-f4049b5e1472",
   "metadata": {},
   "source": [
    "## 🔃 Recursion!\n",
    "\n",
    "We can even do recursion, we took especial care during the definition of `defn` that the environment where the new function is called contains a reference to itself 🙃. Given that this was originally made to apply for *Recurse*, I guess it was only fair I implemented it.\n",
    "\n",
    "### 🐰 Factorial & Fibonacci \n",
    "\n",
    "Classic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a532afc-7650-409d-aead-95a384ed53af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial [1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880]\n",
      "Fibonacci [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n"
     ]
    }
   ],
   "source": [
    "interpret('''\n",
    "(defn map (f xs)\n",
    "    (reduce (fn (acc x) (concat acc (list (f x)))) \n",
    "    (list) xs)\n",
    ")\n",
    "\n",
    "(defn factorial (n)\n",
    "    (if (= n 0)\n",
    "        1\n",
    "        (* n (factorial (- n 1)))))\n",
    "        \n",
    "(print \"Factorial\" (map factorial (range 10)))        \n",
    "\n",
    "(defn fib (n)\n",
    "    (if (or (= n 0) (= n 1)) \n",
    "        1\n",
    "        (+ (fib (- n 1)) (fib (- n 2)))))\n",
    "        \n",
    "(print \"Fibonacci\" (map fib (range 10)))\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58420e30-d762-45c1-9a77-a08dc7b67181",
   "metadata": {},
   "source": [
    "# Imports!\n",
    "\n",
    "We can now do imports that work like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5a58cdc-5283-4a2d-8d5c-52480dba0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3628800\n"
     ]
    }
   ],
   "source": [
    "interpret('''\n",
    "(import './core.lspy' *)\n",
    "(print (factorial 10))\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263b54e-0839-4099-ab5a-92cecc4c8df3",
   "metadata": {},
   "source": [
    "# Why U no REPL? \n",
    "(╯°□°)╯︵ ┻━┻\n",
    "\n",
    "Wouldn't it be cool if we could run this interactively?!\n",
    "\n",
    "It turns out it's way easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e75b71-ec5c-4fc7-ae57-481fad6af814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "def repl():\n",
    "    env = dict(macros, **operators)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            code = input('>>')\n",
    "            asts = parse(tokenize(code))\n",
    "\n",
    "            result = None\n",
    "            for ast in asts:\n",
    "                try:\n",
    "                    result, env = evaluate(ast, **env)\n",
    "                except Exception as e:\n",
    "                    traceback.print_exc() # print exceptions nicely\n",
    "                    continue\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Exiting...\")\n",
    "            return\n",
    "        \n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "898c54be-a5a7-4ec3-9140-50f6f7f2a241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> (print \"hello world\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> (def a 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> (print a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> (def a 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> (print a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "None\n",
      "Exiting...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> \n"
     ]
    }
   ],
   "source": [
    "repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63821de-5029-4c1f-a12f-1cd76dc102ae",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "I'm actually kind of surprised of how simple and powerful lisp is. Laying down the original code took only a couple of hours and this first working version has been a couple afternoons worth of work. I'm a Clojure fan (many of the functions I implemented are simply emulating semantics from Clojure), but I had always assumed that implemeting a programming language was only for real hardcore programmers™️, and that to get event the most basic prototype it would take thousands of lines of code and many months of effort. After breaking it down into smal chunks that I could tackle one by one, I feel I got to build something that feels like a proper (toy) language in only a few hundred lines of Python. Now, I'm sure it has bugs as I haven't any kind of exhastive testing (evidently). \n",
    "\n",
    "One parting thought that is now stirring in the back of my head is what it takes to bootstrap a programming from scratch. I simply built a toy language on top of Python, and it's Python that's doing all the heavy lifting. Making a programming language from nothing seems like a totally different animal. In the case of Lisp, it was originally designed and implemented in ***1960*** (!!). It boggles my mind on how to even begin doing such thing, especially with the tools that were available back then. This has given me a new appreciation for programming languages, all the subtleties that come from making one from scratch, and an incredible respect for those who have paved the for us and on whom's shoulders we now stand on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
